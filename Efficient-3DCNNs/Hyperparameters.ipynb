{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b612d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from subprocess import check_call\n",
    "import sys\n",
    "import json\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553e69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_training_job(pretrain_path, learning_rate):\n",
    "    \"\"\"Launch training of the model with a set of hyperparameters in parent_dir/job_name\n",
    "    Args:\n",
    "        parent_dir: (string) directory containing config, weights and log\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (dict) containing hyperparameters\n",
    "    \"\"\"\n",
    "    # Create a new folder in parent_dir with unique_name \"job_name\"\n",
    "    root_path = \"/home/shared/workspace/\"\n",
    "    pretrain_name = pretrain_path.split('_')[0]\n",
    "    model_name = pretrain_path.split('_')[1]\n",
    "    model_width = pretrain_path.split('_')[2]\n",
    "    print(pretrain_name)\n",
    "    print(model_name)\n",
    "    print(model_width)\n",
    "\n",
    "    result_name = model_name + \"_\" + model_width  + \"_\" + str(50) + \"_\" + str(learning_rate)\n",
    "    result_dir = os.path.join(root_path, 'human-activity-recognition', 'Efficient-3DCNNs', 'data', 'results', result_name)\n",
    "    if not os.path.exists(result_dir):\n",
    "        print(result_dir)\n",
    "#         os.makedirs(result_dir)\n",
    "\n",
    "\n",
    "    # Launch training with this config\n",
    "    num_classes = 600\n",
    "\n",
    "    if pretrain_name == \"kinetics\":\n",
    "        num_classes = 600\n",
    "    elif pretrain_name == \"jester\" :\n",
    "        num_classes = 27\n",
    "    print(num_classes)\n",
    "        \n",
    "    cmd = \"python main.py --root_path /home/shared/workspace/ \\\n",
    "        --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg \\\n",
    "        --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json \\\n",
    "        --result_path {result_dir} \\\n",
    "        --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/{pretrain_path}_RGB_16_best.pth \\\n",
    "        --dataset ucf101 \\\n",
    "        --n_classes {num_classes} \\\n",
    "        --n_finetune_classes 9 \\\n",
    "        --ft_portion last_layer \\\n",
    "        --model {model_name} \\\n",
    "        --groups 3 \\\n",
    "        --width_mult 1.0 \\\n",
    "        --train_crop random \\\n",
    "        --learning_rate {learning_rate} \\\n",
    "        --sample_duration 16 \\\n",
    "        --downsample 1 \\\n",
    "        --n_threads 16 \\\n",
    "        --checkpoint 1 \\\n",
    "        --n_val_samples 1 \\\n",
    "        --batch_size 64 \\\n",
    "        --n_epochs 1\".format(result_dir = result_dir, pretrain_path = pretrain_path, num_classes = num_classes,\n",
    "                             model_name = model_name, learning_rate = learning_rate)\n",
    "    print(cmd)\n",
    "#     check_call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b2b04fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinetics\n",
      "mobilenetv2\n",
      "1.0x\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/mobilenetv2_1.0x_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/mobilenetv2_1.0x_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_mobilenetv2_1.0x_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model mobilenetv2         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n",
      "kinetics\n",
      "shufflenetv2\n",
      "1.0x\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/shufflenetv2_1.0x_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/shufflenetv2_1.0x_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_shufflenetv2_1.0x_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model shufflenetv2         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n",
      "kinetics\n",
      "resnet\n",
      "101\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_101_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_101_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_resnet_101_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model resnet         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n",
      "kinetics\n",
      "resnext\n",
      "101\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnext_101_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnext_101_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_resnext_101_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model resnext         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n",
      "kinetics\n",
      "resnet\n",
      "50\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_50_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_50_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_resnet_50_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model resnet         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n",
      "kinetics\n",
      "resnet\n",
      "18\n",
      "/home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_18_50_0.001\n",
      "600\n",
      "python main.py --root_path /home/shared/workspace/         --video_path Resnet3D/3D-ResNets-PyTorch/data/jpg         --annotation_path Resnet3D/3D-ResNets-PyTorch/data/ntu_01.json         --result_path /home/shared/workspace/human-activity-recognition/Efficient-3DCNNs/data/results/resnet_18_50_0.001         --pretrain_path Resnet3D/3D-ResNets-PyTorch/data/models/kinetics_resnet_18_RGB_16_best.pth         --dataset ucf101         --n_classes 600         --n_finetune_classes 9         --ft_portion last_layer         --model resnet         --groups 3         --width_mult 1.0         --train_crop random         --learning_rate 0.001         --sample_duration 16         --downsample 1         --n_threads 16         --checkpoint 1         --n_val_samples 1         --batch_size 64         --n_epochs 1\n"
     ]
    }
   ],
   "source": [
    "pretrain_path = ['kinetics_mobilenetv2_1.0x', 'kinetics_shufflenetv2_1.0x', 'kinetics_resnet_101', 'kinetics_resnext_101', 'kinetics_resnet_50', 'kinetics_resnet_18']\n",
    "\n",
    "for p in pretrain_path :\n",
    "    launch_training_job(p, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc1e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_inference_job(pretrain_path, model, learning_rate):\n",
    "    \"\"\"Launch training of the model with a set of hyperparameters in parent_dir/job_name\n",
    "    Args:\n",
    "        parent_dir: (string) directory containing config, weights and log\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (dict) containing hyperparameters\n",
    "    \"\"\"\n",
    "    # Create a new folder in parent_dir with unique_name \"job_name\"\n",
    "    root_path = \"/home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data/\"\n",
    "    \n",
    "    result_name = model + \"_\" + pretrain_path.split('.')[0] + \"_\" + str(learning_rate)\n",
    "    result_dir = os.path.join(root_path, 'results', result_name)\n",
    "    if not os.path.exists(result_dir):\n",
    "        print(\"result_dir does not exist\")\n",
    "\n",
    "#     # Write parameters in json file\n",
    "#     json_path = os.path.join(model_dir, 'params.json')\n",
    "#     params.save(json_path)\n",
    "\n",
    "    # Launch training with this config\n",
    "    model_name = pretrain_path.split('.')[0]\n",
    "    model_depth = model_name.split('_')[0].split('d')[-1]\n",
    "    pretrain_dataset = model_name.split('_')[1]\n",
    "\n",
    "    if pretrain_dataset == 'K':\n",
    "        n_pretrain_classes = 700\n",
    "    elif pretrain_dataset == 'KM':\n",
    "        n_pretrain_classes = 1039\n",
    "    elif pretrain_dataset == 'KMS':\n",
    "        n_pretrain_classes = 1139\n",
    "    elif pretrain_dataset == 'M':\n",
    "        n_pretrain_classes = 339\n",
    "    elif pretrain_dataset == 'S':\n",
    "        n_pretrain_classes = 100\n",
    "    else :\n",
    "        n_pretrain_classes = 0\n",
    "        \n",
    "    cmd = \"python main.py --root_path {root_path} \\\n",
    "    --video_path jpg \\\n",
    "    --annotation_path ntu_01.json \\\n",
    "    --result_path {result_dir} \\\n",
    "    --dataset ucf101 \\\n",
    "    --n_classes 9 \\\n",
    "    --model_depth {model_depth} \\\n",
    "    --n_threads 4 \\\n",
    "    --no_train \\\n",
    "    --no_val \\\n",
    "    --inference \\\n",
    "    --output_topk 3\\\n",
    "    --inference_batch_size 1\".format(root_path = root_path, result_dir = result_dir, model_depth = model_depth)\n",
    "    print(cmd)\n",
    "    check_call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09bd82dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python main.py --root_path /home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data/     --video_path jpg     --annotation_path ntu_01.json     --result_path /home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data/results/resnet_r3d50_KMS_200ep_0.0001     --dataset ucf101     --n_classes 9     --model_depth 50     --n_threads 4     --no_train     --no_val     --inference     --output_topk 5    --inference_batch_size 1\n"
     ]
    }
   ],
   "source": [
    "launch_inference_job(\"r3d50_KMS_200ep.pth\", \"resnet\", 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a0514ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_topclass_job(pretrain_path, model, learning_rate):\n",
    "    \"\"\"Launch training of the model with a set of hyperparameters in parent_dir/job_name\n",
    "    Args:\n",
    "        parent_dir: (string) directory containing config, weights and log\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (dict) containing hyperparameters\n",
    "    \"\"\"\n",
    "    # Create a new folder in parent_dir with unique_name \"job_name\"\n",
    "    root_path = \"/home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data/\"\n",
    "    \n",
    "    result_name = model + \"_\" + pretrain_path.split('.')[0] + \"_\" + str(learning_rate)\n",
    "    result_dir = os.path.join(root_path, 'results', result_name)\n",
    "    if not os.path.exists(result_dir):\n",
    "        print(\"result_dir does not exist\")\n",
    "        \n",
    "    cmd = \"python -m util_scripts.eval_accuracy \\\n",
    "    {root_path}/ntu_01.json \\\n",
    "    {result_dir}/val.json \\\n",
    "    --subset validation -k 1 --ignore\".format(root_path = root_path, result_dir = result_dir)\n",
    "    print(cmd)\n",
    "    check_call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e9da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m util_scripts.eval_accuracy     /home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data//ntu_01.json     /home/shared/workspace/Resnet3D/3D-ResNets-PyTorch/data/results/resnet_r3d50_KMS_200ep_0.0001/val.json     --subset validation -k 1 --ignore\n"
     ]
    }
   ],
   "source": [
    "launch_topclass_job(\"r3d50_KMS_200ep.pth\", \"resnet\", 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733feb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
